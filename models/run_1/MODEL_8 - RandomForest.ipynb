{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libraries\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "#visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#model learning libraries\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn import feature_selection\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#hyperparameters\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import optuna\n",
    "from optuna import Trial, study, samplers\n",
    "\n",
    "#pre-build functions\n",
    "from pre_build_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>montage</th>\n",
       "      <th>pilote_id</th>\n",
       "      <th>last_train_idx</th>\n",
       "      <th>len(train)</th>\n",
       "      <th>len(test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-15_16-16-08.palm</td>\n",
       "      <td>1</td>\n",
       "      <td>23337</td>\n",
       "      <td>23337</td>\n",
       "      <td>5810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-15_17-12-24.palm</td>\n",
       "      <td>1</td>\n",
       "      <td>23336</td>\n",
       "      <td>23336</td>\n",
       "      <td>5803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-05_16-12-38.palm</td>\n",
       "      <td>1</td>\n",
       "      <td>17939</td>\n",
       "      <td>17939</td>\n",
       "      <td>4431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    montage  pilote_id  last_train_idx  len(train)  len(test)\n",
       "0  2023-05-15_16-16-08.palm          1           23337       23337       5810\n",
       "1  2023-05-15_17-12-24.palm          1           23336       23336       5803\n",
       "2  2023-06-05_16-12-38.palm          1           17939       17939       4431"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_meta = pd.read_csv('./additional_data/meta_information.csv', index_col=0)\n",
    "data_meta.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the value of the generator\n",
    "length_of_file_number(length=len(data_meta['montage']))\n",
    "n = length_of_file_number(length=len(data_meta['montage']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the features\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.602; 0.68\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((21858, 65), (21858,)) \n",
      " test: ((7287, 65), (7287,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "#create an ordered dict to store model results\n",
    "review = OrderedDict([\n",
    "    ('palm_file', []),\n",
    "    ('model_name', []),\n",
    "    ('learning_time', []),\n",
    "    ('hyperparameters', []),\n",
    "    ('F1-Score, train', []), \n",
    "    ('F1-Score, test', []),\n",
    "    ('F1-Score: Neutral', []),\n",
    "    ('F1-Score: Open', []),\n",
    "    ('F1-Score: Pistol', []),\n",
    "    ('F1-Score: Thumb', []),\n",
    "    ('F1-Score: OK', []),\n",
    "    ('F1-Score: Grab', [])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the Optuna method to look for best hyper parameters\n",
    "def optuna_rf(trial):\n",
    "  #set hyperparameters\n",
    "  n_estimators = trial.suggest_categorical('n_estimators', [100, 125, 150, 175, 200])\n",
    "  max_depth = trial.suggest_categorical('max_depth', [10, 15, 20])\n",
    "  min_samples_leaf = trial.suggest_categorical('min_samples_leaf', [3, 4, 5])\n",
    "  criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "  max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "  \n",
    "  #use the combinations for model build\n",
    "  model = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                          max_depth=max_depth,\n",
    "                                          min_samples_leaf=min_samples_leaf,\n",
    "                                          criterion=criterion,\n",
    "                                          max_features=max_features,\n",
    "                                          random_state=42)\n",
    "  \n",
    "  #model learning through cross-validation\n",
    "  score = model_selection.cross_val_score(\n",
    "    model,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=5,\n",
    "    scoring='f1_micro', \n",
    "    n_jobs=-1).mean()\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:13:36,111] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:14:30,563] Trial 0 finished with value: 0.972733214400912 and parameters: {'n_estimators': 125, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': None}. Best is trial 0 with value: 0.972733214400912.\n",
      "[I 2024-10-08 00:14:36,690] Trial 1 finished with value: 0.8205698667274515 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.972733214400912.\n",
      "[I 2024-10-08 00:14:42,732] Trial 2 finished with value: 0.9792754499578546 and parameters: {'n_estimators': 125, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9792754499578546.\n",
      "[I 2024-10-08 00:14:45,393] Trial 3 finished with value: 0.7881790341104965 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 2 with value: 0.9792754499578546.\n",
      "[I 2024-10-08 00:14:49,700] Trial 4 finished with value: 0.9720470714513418 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 2 with value: 0.9792754499578546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94.2 ms, sys: 115 ms, total: 210 ms\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 125, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.947\n",
      "accuracy: 0.947\n",
      "\n",
      "test data:\n",
      "f1_score: 0.987\n",
      "accuracy: 0.987\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.96      0.98      0.97     14173\n",
      "        Open       0.95      0.83      0.89      1538\n",
      "      Pistol       0.91      0.84      0.88      1535\n",
      "       Thumb       0.89      0.95      0.92      1537\n",
      "          OK       0.93      0.91      0.92      1540\n",
      "        Grab       0.92      0.85      0.88      1535\n",
      "\n",
      "    accuracy                           0.95     21858\n",
      "   macro avg       0.93      0.90      0.91     21858\n",
      "weighted avg       0.95      0.95      0.95     21858\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.99      0.99      0.99      4725\n",
      "        Open       0.99      0.97      0.98       513\n",
      "      Pistol       0.99      0.98      0.98       511\n",
      "       Thumb       0.96      0.98      0.97       512\n",
      "          OK       0.99      0.98      0.98       514\n",
      "        Grab       0.99      0.97      0.98       512\n",
      "\n",
      "    accuracy                           0.99      7287\n",
      "   macro avg       0.98      0.98      0.98      7287\n",
      "weighted avg       0.99      0.99      0.99      7287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   20 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.62; 0.683\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 10']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((21852, 65), (21852,)) \n",
      " test: ((7285, 65), (7285,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:15:05,320] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:16:00,660] Trial 0 finished with value: 0.881291683746683 and parameters: {'n_estimators': 150, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.881291683746683.\n",
      "[I 2024-10-08 00:16:46,784] Trial 1 finished with value: 0.785374281395949 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': None}. Best is trial 0 with value: 0.881291683746683.\n",
      "[I 2024-10-08 00:17:25,476] Trial 2 finished with value: 0.8558480038238295 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': None}. Best is trial 0 with value: 0.881291683746683.\n",
      "[I 2024-10-08 00:17:28,103] Trial 3 finished with value: 0.729177819066481 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 0 with value: 0.881291683746683.\n",
      "[I 2024-10-08 00:17:33,250] Trial 4 finished with value: 0.8488006294869399 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.881291683746683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 131 ms, sys: 88.6 ms, total: 219 ms\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 150, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.827\n",
      "accuracy: 0.827\n",
      "\n",
      "test data:\n",
      "f1_score: 0.966\n",
      "accuracy: 0.966\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.85      0.92      0.88     14146\n",
      "        Open       0.89      0.70      0.79      1540\n",
      "      Pistol       0.69      0.60      0.64      1540\n",
      "       Thumb       0.67      0.68      0.67      1541\n",
      "          OK       0.82      0.66      0.73      1542\n",
      "        Grab       0.86      0.62      0.72      1543\n",
      "\n",
      "    accuracy                           0.83     21852\n",
      "   macro avg       0.79      0.70      0.74     21852\n",
      "weighted avg       0.83      0.83      0.82     21852\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.95      1.00      0.98      4716\n",
      "        Open       1.00      0.97      0.98       514\n",
      "      Pistol       1.00      0.90      0.94       513\n",
      "       Thumb       0.97      0.86      0.91       514\n",
      "          OK       1.00      0.89      0.94       514\n",
      "        Grab       0.99      0.92      0.96       514\n",
      "\n",
      "    accuracy                           0.97      7285\n",
      "   macro avg       0.98      0.92      0.95      7285\n",
      "weighted avg       0.97      0.97      0.97      7285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.61; 0.58\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((16776, 65), (16776,)) \n",
      " test: ((5592, 65), (5592,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:19:09,750] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:19:14,889] Trial 0 finished with value: 0.9617907557965004 and parameters: {'n_estimators': 125, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9617907557965004.\n",
      "[I 2024-10-08 00:19:17,735] Trial 1 finished with value: 0.7872565629723839 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.9617907557965004.\n",
      "[I 2024-10-08 00:20:10,656] Trial 2 finished with value: 0.9076063158006924 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': None}. Best is trial 0 with value: 0.9617907557965004.\n",
      "[I 2024-10-08 00:20:15,937] Trial 3 finished with value: 0.8586667471921189 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9617907557965004.\n",
      "[I 2024-10-08 00:20:21,968] Trial 4 finished with value: 0.9601216763267605 and parameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.9617907557965004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 107 ms, sys: 57.8 ms, total: 165 ms\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 125, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.929\n",
      "accuracy: 0.929\n",
      "\n",
      "test data:\n",
      "f1_score: 0.983\n",
      "accuracy: 0.983\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.95      0.97      0.96      9970\n",
      "        Open       0.93      0.89      0.91      1363\n",
      "      Pistol       0.84      0.86      0.85      1355\n",
      "       Thumb       0.88      0.94      0.91      1362\n",
      "          OK       0.91      0.86      0.89      1363\n",
      "        Grab       0.94      0.82      0.87      1363\n",
      "\n",
      "    accuracy                           0.93     16776\n",
      "   macro avg       0.91      0.89      0.90     16776\n",
      "weighted avg       0.93      0.93      0.93     16776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.98      0.99      0.99      3324\n",
      "        Open       0.98      0.99      0.98       455\n",
      "      Pistol       0.99      0.96      0.98       451\n",
      "       Thumb       0.97      0.97      0.97       454\n",
      "          OK       0.98      0.97      0.98       454\n",
      "        Grab       0.99      0.96      0.97       454\n",
      "\n",
      "    accuracy                           0.98      5592\n",
      "   macro avg       0.98      0.97      0.98      5592\n",
      "weighted avg       0.98      0.98      0.98      5592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.574; 0.576\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((16653, 65), (16653,)) \n",
      " test: ((5551, 65), (5551,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:20:37,250] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:20:41,720] Trial 0 finished with value: 0.8574418489338935 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8574418489338935.\n",
      "[I 2024-10-08 00:20:44,730] Trial 1 finished with value: 0.7618446426011722 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 0 with value: 0.8574418489338935.\n",
      "[I 2024-10-08 00:21:23,437] Trial 2 finished with value: 0.9535817414532515 and parameters: {'n_estimators': 150, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 2 with value: 0.9535817414532515.\n",
      "[I 2024-10-08 00:21:26,586] Trial 3 finished with value: 0.8145083720766699 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 2 with value: 0.9535817414532515.\n",
      "[I 2024-10-08 00:21:30,404] Trial 4 finished with value: 0.9541221918405947 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9541221918405947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 134 ms, sys: 56.3 ms, total: 191 ms\n",
      "Wall time: 53.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.919\n",
      "accuracy: 0.919\n",
      "\n",
      "test data:\n",
      "f1_score: 0.974\n",
      "accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.94      0.97      0.95      9797\n",
      "        Open       0.94      0.81      0.87      1369\n",
      "      Pistol       0.89      0.82      0.86      1379\n",
      "       Thumb       0.85      0.92      0.88      1367\n",
      "          OK       0.88      0.90      0.89      1366\n",
      "        Grab       0.92      0.80      0.85      1375\n",
      "\n",
      "    accuracy                           0.92     16653\n",
      "   macro avg       0.90      0.87      0.88     16653\n",
      "weighted avg       0.92      0.92      0.92     16653\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.98      0.98      0.98      3265\n",
      "        Open       0.99      0.95      0.97       456\n",
      "      Pistol       0.97      0.96      0.96       460\n",
      "       Thumb       0.96      0.98      0.97       456\n",
      "          OK       0.93      0.98      0.95       456\n",
      "        Grab       0.98      0.95      0.96       458\n",
      "\n",
      "    accuracy                           0.97      5551\n",
      "   macro avg       0.97      0.97      0.97      5551\n",
      "weighted avg       0.97      0.97      0.97      5551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.612; 0.588\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((16781, 65), (16781,)) \n",
      " test: ((5594, 65), (5594,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:21:42,851] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:22:36,281] Trial 0 finished with value: 0.9221141279513784 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': None}. Best is trial 0 with value: 0.9221141279513784.\n",
      "[I 2024-10-08 00:22:41,703] Trial 1 finished with value: 0.8767653060173839 and parameters: {'n_estimators': 175, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9221141279513784.\n",
      "[I 2024-10-08 00:22:47,986] Trial 2 finished with value: 0.945771612729596 and parameters: {'n_estimators': 175, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 2 with value: 0.945771612729596.\n",
      "[I 2024-10-08 00:23:25,300] Trial 3 finished with value: 0.9428518247498777 and parameters: {'n_estimators': 150, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 2 with value: 0.945771612729596.\n",
      "[I 2024-10-08 00:23:29,678] Trial 4 finished with value: 0.8263513026522418 and parameters: {'n_estimators': 175, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 2 with value: 0.945771612729596.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 133 ms, sys: 79.5 ms, total: 212 ms\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 175, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.920\n",
      "accuracy: 0.920\n",
      "\n",
      "test data:\n",
      "f1_score: 0.971\n",
      "accuracy: 0.971\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.95      0.97      0.96      9937\n",
      "        Open       0.95      0.79      0.86      1376\n",
      "      Pistol       0.83      0.86      0.84      1367\n",
      "       Thumb       0.90      0.92      0.91      1367\n",
      "          OK       0.84      0.87      0.86      1363\n",
      "        Grab       0.90      0.80      0.85      1371\n",
      "\n",
      "    accuracy                           0.92     16781\n",
      "   macro avg       0.89      0.87      0.88     16781\n",
      "weighted avg       0.92      0.92      0.92     16781\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.97      0.98      0.98      3313\n",
      "        Open       0.99      0.95      0.97       459\n",
      "      Pistol       0.94      0.95      0.95       456\n",
      "       Thumb       0.96      0.96      0.96       455\n",
      "          OK       0.96      0.94      0.95       454\n",
      "        Grab       0.98      0.95      0.96       457\n",
      "\n",
      "    accuracy                           0.97      5594\n",
      "   macro avg       0.97      0.96      0.96      5594\n",
      "weighted avg       0.97      0.97      0.97      5594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.602; 0.578\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((16770, 65), (16770,)) \n",
      " test: ((5591, 65), (5591,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:23:46,486] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:23:52,178] Trial 0 finished with value: 0.9587954680977937 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.9587954680977937.\n",
      "[I 2024-10-08 00:24:36,558] Trial 1 finished with value: 0.95855694692904 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.9587954680977937.\n",
      "[I 2024-10-08 00:25:36,274] Trial 2 finished with value: 0.9547406082289804 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': None}. Best is trial 0 with value: 0.9587954680977937.\n",
      "[I 2024-10-08 00:25:40,537] Trial 3 finished with value: 0.9236135957066189 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9587954680977937.\n",
      "[I 2024-10-08 00:25:45,724] Trial 4 finished with value: 0.9610614192009541 and parameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 4 with value: 0.9610614192009541.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 133 ms, sys: 80.9 ms, total: 214 ms\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.932\n",
      "accuracy: 0.932\n",
      "\n",
      "test data:\n",
      "f1_score: 0.985\n",
      "accuracy: 0.985\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.94      0.98      0.96      9881\n",
      "        Open       0.96      0.85      0.90      1385\n",
      "      Pistol       0.92      0.85      0.88      1378\n",
      "       Thumb       0.90      0.93      0.92      1381\n",
      "          OK       0.93      0.89      0.91      1375\n",
      "        Grab       0.93      0.83      0.87      1370\n",
      "\n",
      "    accuracy                           0.93     16770\n",
      "   macro avg       0.93      0.89      0.91     16770\n",
      "weighted avg       0.93      0.93      0.93     16770\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.98      0.99      0.99      3294\n",
      "        Open       1.00      0.98      0.99       462\n",
      "      Pistol       0.99      0.97      0.98       459\n",
      "       Thumb       0.99      0.96      0.97       461\n",
      "          OK       0.99      0.97      0.98       458\n",
      "        Grab       0.98      0.98      0.98       457\n",
      "\n",
      "    accuracy                           0.98      5591\n",
      "   macro avg       0.99      0.98      0.98      5591\n",
      "weighted avg       0.98      0.98      0.98      5591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.57; 0.594\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((16650, 65), (16650,)) \n",
      " test: ((5550, 65), (5550,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:26:00,159] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:26:33,377] Trial 0 finished with value: 0.9448048048048048 and parameters: {'n_estimators': 150, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.9448048048048048.\n",
      "[I 2024-10-08 00:26:40,610] Trial 1 finished with value: 0.9606006006006007 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9606006006006007.\n",
      "[I 2024-10-08 00:27:08,650] Trial 2 finished with value: 0.8701501501501502 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.9606006006006007.\n",
      "[I 2024-10-08 00:27:12,094] Trial 3 finished with value: 0.8183183183183182 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 1 with value: 0.9606006006006007.\n",
      "[I 2024-10-08 00:27:52,195] Trial 4 finished with value: 0.9555555555555555 and parameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.9606006006006007.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 122 ms, sys: 73.6 ms, total: 196 ms\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.927\n",
      "accuracy: 0.927\n",
      "\n",
      "test data:\n",
      "f1_score: 0.979\n",
      "accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.95      0.97      0.96      9780\n",
      "        Open       0.94      0.82      0.88      1377\n",
      "      Pistol       0.89      0.84      0.87      1370\n",
      "       Thumb       0.85      0.91      0.88      1366\n",
      "          OK       0.89      0.90      0.89      1379\n",
      "        Grab       0.92      0.83      0.87      1378\n",
      "\n",
      "    accuracy                           0.93     16650\n",
      "   macro avg       0.91      0.88      0.89     16650\n",
      "weighted avg       0.93      0.93      0.93     16650\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.98      0.99      0.98      3260\n",
      "        Open       0.99      0.97      0.98       459\n",
      "      Pistol       0.98      0.96      0.97       457\n",
      "       Thumb       0.97      0.97      0.97       455\n",
      "          OK       0.98      0.96      0.97       460\n",
      "        Grab       0.98      0.97      0.97       459\n",
      "\n",
      "    accuracy                           0.98      5550\n",
      "   macro avg       0.98      0.97      0.98      5550\n",
      "weighted avg       0.98      0.98      0.98      5550\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.599; 0.58\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((8400, 65), (8400,)) \n",
      " test: ((2800, 65), (2800,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:28:10,372] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:28:12,785] Trial 0 finished with value: 0.9620238095238095 and parameters: {'n_estimators': 125, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9620238095238095.\n",
      "[I 2024-10-08 00:28:16,717] Trial 1 finished with value: 0.968095238095238 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.968095238095238.\n",
      "[I 2024-10-08 00:28:31,614] Trial 2 finished with value: 0.9564285714285715 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.968095238095238.\n",
      "[I 2024-10-08 00:28:49,262] Trial 3 finished with value: 0.9577380952380953 and parameters: {'n_estimators': 175, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.968095238095238.\n",
      "[I 2024-10-08 00:29:07,383] Trial 4 finished with value: 0.9475 and parameters: {'n_estimators': 175, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': None}. Best is trial 1 with value: 0.968095238095238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 82 ms, sys: 47.6 ms, total: 130 ms\n",
      "Wall time: 57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.938\n",
      "accuracy: 0.938\n",
      "\n",
      "test data:\n",
      "f1_score: 0.986\n",
      "accuracy: 0.986\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.95      0.98      0.96      4966\n",
      "        Open       0.92      0.94      0.93       688\n",
      "      Pistol       0.93      0.83      0.88       687\n",
      "       Thumb       0.92      0.89      0.90       685\n",
      "          OK       0.94      0.85      0.89       688\n",
      "        Grab       0.91      0.91      0.91       686\n",
      "\n",
      "    accuracy                           0.94      8400\n",
      "   macro avg       0.93      0.90      0.91      8400\n",
      "weighted avg       0.94      0.94      0.94      8400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.98      1.00      0.99      1655\n",
      "        Open       0.99      0.98      0.98       229\n",
      "      Pistol       1.00      0.94      0.97       229\n",
      "       Thumb       0.99      0.97      0.98       229\n",
      "          OK       1.00      0.98      0.99       229\n",
      "        Grab       1.00      0.98      0.99       229\n",
      "\n",
      "    accuracy                           0.99      2800\n",
      "   macro avg       0.99      0.97      0.98      2800\n",
      "weighted avg       0.99      0.99      0.99      2800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.602; 0.579\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((8402, 65), (8402,)) \n",
      " test: ((2801, 65), (2801,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:29:19,810] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:29:21,441] Trial 0 finished with value: 0.9538210673918586 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 0 with value: 0.9538210673918586.\n",
      "[I 2024-10-08 00:29:23,974] Trial 1 finished with value: 0.9682215801252088 and parameters: {'n_estimators': 125, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9682215801252088.\n",
      "[I 2024-10-08 00:29:34,834] Trial 2 finished with value: 0.9634611625732982 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.9682215801252088.\n",
      "[I 2024-10-08 00:29:36,941] Trial 3 finished with value: 0.9646509305685391 and parameters: {'n_estimators': 125, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 1 with value: 0.9682215801252088.\n",
      "[I 2024-10-08 00:29:38,767] Trial 4 finished with value: 0.9053791677289595 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 1 with value: 0.9682215801252088.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.6 ms, sys: 32.6 ms, total: 91.3 ms\n",
      "Wall time: 19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 125, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.931\n",
      "accuracy: 0.931\n",
      "\n",
      "test data:\n",
      "f1_score: 0.979\n",
      "accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.92      0.98      0.95      4971\n",
      "        Open       0.93      0.91      0.92       685\n",
      "      Pistol       0.96      0.76      0.85       686\n",
      "       Thumb       0.95      0.90      0.93       688\n",
      "          OK       0.94      0.84      0.88       686\n",
      "        Grab       0.96      0.88      0.92       686\n",
      "\n",
      "    accuracy                           0.93      8402\n",
      "   macro avg       0.94      0.88      0.91      8402\n",
      "weighted avg       0.93      0.93      0.93      8402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.97      0.99      0.98      1657\n",
      "        Open       0.98      0.96      0.97       229\n",
      "      Pistol       0.99      0.93      0.96       228\n",
      "       Thumb       1.00      0.97      0.98       230\n",
      "          OK       0.99      0.96      0.98       228\n",
      "        Grab       0.98      0.96      0.97       229\n",
      "\n",
      "    accuracy                           0.98      2801\n",
      "   macro avg       0.99      0.96      0.97      2801\n",
      "weighted avg       0.98      0.98      0.98      2801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.601; 0.578\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((8396, 65), (8396,)) \n",
      " test: ((2799, 65), (2799,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:29:48,679] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:30:10,034] Trial 0 finished with value: 0.9655794265293969 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.9655794265293969.\n",
      "[I 2024-10-08 00:30:12,620] Trial 1 finished with value: 0.9610532771774583 and parameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 0 with value: 0.9655794265293969.\n",
      "[I 2024-10-08 00:30:33,117] Trial 2 finished with value: 0.9642693354888113 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.9655794265293969.\n",
      "[I 2024-10-08 00:30:51,011] Trial 3 finished with value: 0.9590282622876428 and parameters: {'n_estimators': 150, 'max_depth': 15, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': None}. Best is trial 0 with value: 0.9655794265293969.\n",
      "[I 2024-10-08 00:30:52,914] Trial 4 finished with value: 0.9661745937207522 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9661745937207522.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 95.1 ms, sys: 51.3 ms, total: 146 ms\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.929\n",
      "accuracy: 0.929\n",
      "\n",
      "test data:\n",
      "f1_score: 0.982\n",
      "accuracy: 0.982\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.91      0.98      0.95      4965\n",
      "        Open       0.97      0.85      0.91       685\n",
      "      Pistol       0.96      0.82      0.88       688\n",
      "       Thumb       0.94      0.86      0.90       687\n",
      "          OK       0.95      0.88      0.91       686\n",
      "        Grab       0.96      0.87      0.91       685\n",
      "\n",
      "    accuracy                           0.93      8396\n",
      "   macro avg       0.95      0.88      0.91      8396\n",
      "weighted avg       0.93      0.93      0.93      8396\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.97      1.00      0.99      1655\n",
      "        Open       0.99      0.97      0.98       229\n",
      "      Pistol       1.00      0.94      0.97       229\n",
      "       Thumb       1.00      0.97      0.98       229\n",
      "          OK       1.00      0.97      0.98       229\n",
      "        Grab       0.99      0.97      0.98       228\n",
      "\n",
      "    accuracy                           0.98      2799\n",
      "   macro avg       0.99      0.97      0.98      2799\n",
      "weighted avg       0.98      0.98      0.98      2799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.599; 0.583\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((4288, 65), (4288,)) \n",
      " test: ((1430, 65), (1430,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:31:01,266] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:31:03,008] Trial 0 finished with value: 0.9542916826464085 and parameters: {'n_estimators': 150, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9542916826464085.\n",
      "[I 2024-10-08 00:31:04,529] Trial 1 finished with value: 0.9158119204793651 and parameters: {'n_estimators': 175, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.9542916826464085.\n",
      "[I 2024-10-08 00:31:05,292] Trial 2 finished with value: 0.8526123817839103 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 0 with value: 0.9542916826464085.\n",
      "[I 2024-10-08 00:31:06,706] Trial 3 finished with value: 0.947994440409843 and parameters: {'n_estimators': 125, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9542916826464085.\n",
      "[I 2024-10-08 00:31:08,196] Trial 4 finished with value: 0.954990983345709 and parameters: {'n_estimators': 125, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 4 with value: 0.954990983345709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.5 ms, sys: 18.4 ms, total: 57.9 ms\n",
      "Wall time: 6.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 125, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.910\n",
      "accuracy: 0.910\n",
      "\n",
      "test data:\n",
      "f1_score: 0.988\n",
      "accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.88      0.98      0.93      2568\n",
      "        Open       0.96      0.81      0.87       342\n",
      "      Pistol       0.97      0.84      0.90       344\n",
      "       Thumb       0.98      0.72      0.83       345\n",
      "          OK       0.96      0.86      0.91       343\n",
      "        Grab       0.96      0.77      0.86       346\n",
      "\n",
      "    accuracy                           0.91      4288\n",
      "   macro avg       0.95      0.83      0.88      4288\n",
      "weighted avg       0.92      0.91      0.91      4288\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.98      1.00      0.99       857\n",
      "        Open       1.00      0.97      0.99       114\n",
      "      Pistol       1.00      0.97      0.99       115\n",
      "       Thumb       1.00      0.97      0.98       115\n",
      "          OK       0.99      0.97      0.98       114\n",
      "        Grab       1.00      0.97      0.99       115\n",
      "\n",
      "    accuracy                           0.99      1430\n",
      "   macro avg       1.00      0.98      0.99      1430\n",
      "weighted avg       0.99      0.99      0.99      1430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.604; 0.581\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((4275, 65), (4275,)) \n",
      " test: ((1426, 65), (1426,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:31:15,831] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:31:17,900] Trial 0 finished with value: 0.9604678362573098 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9604678362573098.\n",
      "[I 2024-10-08 00:31:18,988] Trial 1 finished with value: 0.888421052631579 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 0 with value: 0.9604678362573098.\n",
      "[I 2024-10-08 00:31:20,634] Trial 2 finished with value: 0.9574269005847954 and parameters: {'n_estimators': 175, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.9604678362573098.\n",
      "[I 2024-10-08 00:31:30,876] Trial 3 finished with value: 0.9560233918128656 and parameters: {'n_estimators': 175, 'max_depth': 15, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.9604678362573098.\n",
      "[I 2024-10-08 00:31:37,771] Trial 4 finished with value: 0.9536842105263158 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.9604678362573098.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 ms, sys: 25.6 ms, total: 77.6 ms\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.928\n",
      "accuracy: 0.928\n",
      "\n",
      "test data:\n",
      "f1_score: 0.989\n",
      "accuracy: 0.989\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.91      0.98      0.95      2555\n",
      "        Open       0.97      0.83      0.89       345\n",
      "      Pistol       0.93      0.84      0.88       343\n",
      "       Thumb       0.97      0.85      0.91       344\n",
      "          OK       0.96      0.89      0.92       343\n",
      "        Grab       0.94      0.86      0.90       345\n",
      "\n",
      "    accuracy                           0.93      4275\n",
      "   macro avg       0.95      0.87      0.91      4275\n",
      "weighted avg       0.93      0.93      0.93      4275\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.99      0.99      0.99       852\n",
      "        Open       0.99      0.99      0.99       115\n",
      "      Pistol       0.98      0.99      0.99       114\n",
      "       Thumb       0.97      0.99      0.98       115\n",
      "          OK       0.98      0.97      0.98       115\n",
      "        Grab       0.99      0.99      0.99       115\n",
      "\n",
      "    accuracy                           0.99      1426\n",
      "   macro avg       0.99      0.99      0.99      1426\n",
      "weighted avg       0.99      0.99      0.99      1426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.605; 0.579\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((4276, 65), (4276,)) \n",
      " test: ((1426, 65), (1426,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:31:46,548] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:31:51,408] Trial 0 finished with value: 0.9611783352462151 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.9611783352462151.\n",
      "[I 2024-10-08 00:31:52,699] Trial 1 finished with value: 0.9529947532382359 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9611783352462151.\n",
      "[I 2024-10-08 00:31:53,729] Trial 2 finished with value: 0.9600071049898891 and parameters: {'n_estimators': 125, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.9611783352462151.\n",
      "[I 2024-10-08 00:32:00,425] Trial 3 finished with value: 0.9637508881237361 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': None}. Best is trial 3 with value: 0.9637508881237361.\n",
      "[I 2024-10-08 00:32:02,014] Trial 4 finished with value: 0.9609430507733508 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 3 with value: 0.9637508881237361.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50 ms, sys: 23.8 ms, total: 73.8 ms\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.962\n",
      "accuracy: 0.962\n",
      "\n",
      "test data:\n",
      "f1_score: 0.978\n",
      "accuracy: 0.978\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.98      0.97      0.97      2563\n",
      "        Open       0.97      0.97      0.97       342\n",
      "      Pistol       0.93      0.94      0.93       343\n",
      "       Thumb       0.90      0.96      0.93       343\n",
      "          OK       0.94      0.94      0.94       342\n",
      "        Grab       0.97      0.94      0.96       343\n",
      "\n",
      "    accuracy                           0.96      4276\n",
      "   macro avg       0.95      0.95      0.95      4276\n",
      "weighted avg       0.96      0.96      0.96      4276\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.97      0.99      0.98       855\n",
      "        Open       0.98      0.96      0.97       114\n",
      "      Pistol       0.97      0.98      0.98       115\n",
      "       Thumb       0.99      0.95      0.97       114\n",
      "          OK       0.99      0.93      0.96       114\n",
      "        Grab       0.98      0.96      0.97       114\n",
      "\n",
      "    accuracy                           0.98      1426\n",
      "   macro avg       0.98      0.96      0.97      1426\n",
      "weighted avg       0.98      0.98      0.98      1426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   20 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.627; 0.678\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 10']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((14676, 65), (14676,)) \n",
      " test: ((4892, 65), (4892,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:32:16,849] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:32:20,526] Trial 0 finished with value: 0.8965660844176039 and parameters: {'n_estimators': 125, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8965660844176039.\n",
      "[I 2024-10-08 00:32:54,705] Trial 1 finished with value: 0.9200056166997015 and parameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.9200056166997015.\n",
      "[I 2024-10-08 00:32:57,732] Trial 2 finished with value: 0.8712866187931987 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 1 with value: 0.9200056166997015.\n",
      "[I 2024-10-08 00:33:01,383] Trial 3 finished with value: 0.8965660844176039 and parameters: {'n_estimators': 125, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9200056166997015.\n",
      "[I 2024-10-08 00:33:04,832] Trial 4 finished with value: 0.8546609091626474 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 1 with value: 0.9200056166997015.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84.5 ms, sys: 48.4 ms, total: 133 ms\n",
      "Wall time: 48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.887\n",
      "accuracy: 0.887\n",
      "\n",
      "test data:\n",
      "f1_score: 0.969\n",
      "accuracy: 0.969\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.88      0.97      0.92      9494\n",
      "        Open       0.94      0.78      0.86      1035\n",
      "      Pistol       0.93      0.74      0.82      1031\n",
      "       Thumb       0.90      0.70      0.79      1035\n",
      "          OK       0.84      0.70      0.77      1035\n",
      "        Grab       0.89      0.79      0.84      1046\n",
      "\n",
      "    accuracy                           0.89     14676\n",
      "   macro avg       0.90      0.78      0.83     14676\n",
      "weighted avg       0.89      0.89      0.88     14676\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.96      0.99      0.98      3165\n",
      "        Open       0.97      0.92      0.95       345\n",
      "      Pistol       0.99      0.92      0.95       343\n",
      "       Thumb       0.99      0.92      0.95       345\n",
      "          OK       0.98      0.92      0.95       345\n",
      "        Grab       0.99      0.93      0.96       349\n",
      "\n",
      "    accuracy                           0.97      4892\n",
      "   macro avg       0.98      0.93      0.96      4892\n",
      "weighted avg       0.97      0.97      0.97      4892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   20 и 3\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.619; 0.677\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 12']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((14674, 65), (14674,)) \n",
      " test: ((4892, 65), (4892,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:34:05,749] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:34:10,246] Trial 0 finished with value: 0.9291945341522583 and parameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.9291945341522583.\n",
      "[I 2024-10-08 00:34:13,122] Trial 1 finished with value: 0.9176774676035763 and parameters: {'n_estimators': 125, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 0 with value: 0.9291945341522583.\n",
      "[I 2024-10-08 00:34:57,172] Trial 2 finished with value: 0.945754677870563 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 2 with value: 0.945754677870563.\n",
      "[I 2024-10-08 00:35:42,565] Trial 3 finished with value: 0.9488212567455051 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': None}. Best is trial 3 with value: 0.9488212567455051.\n",
      "[I 2024-10-08 00:35:45,556] Trial 4 finished with value: 0.8737903380329776 and parameters: {'n_estimators': 175, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 3 with value: 0.9488212567455051.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 126 ms, sys: 74.4 ms, total: 201 ms\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.929\n",
      "accuracy: 0.929\n",
      "\n",
      "test data:\n",
      "f1_score: 0.990\n",
      "accuracy: 0.990\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.92      0.98      0.95      9492\n",
      "        Open       0.99      0.88      0.93      1035\n",
      "      Pistol       0.96      0.83      0.89      1041\n",
      "       Thumb       0.93      0.81      0.86      1024\n",
      "          OK       0.94      0.78      0.85      1043\n",
      "        Grab       0.95      0.85      0.90      1039\n",
      "\n",
      "    accuracy                           0.93     14674\n",
      "   macro avg       0.95      0.86      0.90     14674\n",
      "weighted avg       0.93      0.93      0.93     14674\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.99      1.00      0.99      3164\n",
      "        Open       1.00      0.97      0.99       345\n",
      "      Pistol       1.00      0.97      0.98       347\n",
      "       Thumb       1.00      0.98      0.99       342\n",
      "          OK       0.99      0.98      0.99       348\n",
      "        Grab       1.00      0.97      0.98       346\n",
      "\n",
      "    accuracy                           0.99      4892\n",
      "   macro avg       0.99      0.98      0.99      4892\n",
      "weighted avg       0.99      0.99      0.99      4892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   20 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.616; 0.679\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 10']"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((14604, 65), (14604,)) \n",
      " test: ((4868, 65), (4868,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:37:05,277] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:37:08,172] Trial 0 finished with value: 0.9176942593313419 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.9176942593313419.\n",
      "[I 2024-10-08 00:37:11,928] Trial 1 finished with value: 0.9236515454924895 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9236515454924895.\n",
      "[I 2024-10-08 00:37:15,143] Trial 2 finished with value: 0.9207071841600503 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 1 with value: 0.9236515454924895.\n",
      "[I 2024-10-08 00:37:21,610] Trial 3 finished with value: 0.9215289378285725 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9236515454924895.\n",
      "[I 2024-10-08 00:37:25,876] Trial 4 finished with value: 0.9205702213072084 and parameters: {'n_estimators': 150, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 1 with value: 0.9236515454924895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 64.9 ms, sys: 33.7 ms, total: 98.7 ms\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.918\n",
      "accuracy: 0.918\n",
      "\n",
      "test data:\n",
      "f1_score: 0.978\n",
      "accuracy: 0.978\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.90      0.98      0.94      9455\n",
      "        Open       0.98      0.80      0.88      1032\n",
      "      Pistol       0.98      0.81      0.89      1031\n",
      "       Thumb       0.96      0.86      0.90      1029\n",
      "          OK       0.94      0.74      0.83      1028\n",
      "        Grab       0.96      0.79      0.86      1029\n",
      "\n",
      "    accuracy                           0.92     14604\n",
      "   macro avg       0.95      0.83      0.88     14604\n",
      "weighted avg       0.92      0.92      0.92     14604\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.97      1.00      0.98      3152\n",
      "        Open       1.00      0.92      0.95       344\n",
      "      Pistol       0.99      0.93      0.96       343\n",
      "       Thumb       1.00      0.94      0.97       343\n",
      "          OK       0.99      0.97      0.98       343\n",
      "        Grab       1.00      0.95      0.97       343\n",
      "\n",
      "    accuracy                           0.98      4868\n",
      "   macro avg       0.99      0.95      0.97      4868\n",
      "weighted avg       0.98      0.98      0.98      4868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   20 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.616; 0.68\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 10']"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((21812, 65), (21812,)) \n",
      " test: ((7271, 65), (7271,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:37:36,957] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:37:48,320] Trial 0 finished with value: 0.9289839857338968 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9289839857338968.\n",
      "[I 2024-10-08 00:37:52,861] Trial 1 finished with value: 0.8963871613058962 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 0 with value: 0.9289839857338968.\n",
      "[I 2024-10-08 00:38:44,340] Trial 2 finished with value: 0.9362278646149422 and parameters: {'n_estimators': 150, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': None}. Best is trial 2 with value: 0.9362278646149422.\n",
      "[I 2024-10-08 00:39:51,456] Trial 3 finished with value: 0.9300384322629658 and parameters: {'n_estimators': 150, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': None}. Best is trial 2 with value: 0.9362278646149422.\n",
      "[I 2024-10-08 00:40:29,164] Trial 4 finished with value: 0.9183936488980372 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': None}. Best is trial 2 with value: 0.9362278646149422.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 179 ms, sys: 108 ms, total: 287 ms\n",
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 150, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.918\n",
      "accuracy: 0.918\n",
      "\n",
      "test data:\n",
      "f1_score: 0.987\n",
      "accuracy: 0.987\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.91      0.97      0.94     14092\n",
      "        Open       0.95      0.85      0.89      1546\n",
      "      Pistol       0.92      0.81      0.86      1546\n",
      "       Thumb       0.95      0.89      0.92      1543\n",
      "          OK       0.90      0.75      0.82      1541\n",
      "        Grab       0.92      0.81      0.86      1544\n",
      "\n",
      "    accuracy                           0.92     21812\n",
      "   macro avg       0.93      0.85      0.88     21812\n",
      "weighted avg       0.92      0.92      0.92     21812\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.99      1.00      0.99      4698\n",
      "        Open       1.00      0.97      0.99       515\n",
      "      Pistol       0.99      0.96      0.98       516\n",
      "       Thumb       0.99      0.97      0.98       514\n",
      "          OK       0.99      0.97      0.98       514\n",
      "        Grab       0.99      0.98      0.98       514\n",
      "\n",
      "    accuracy                           0.99      7271\n",
      "   macro avg       0.99      0.98      0.98      7271\n",
      "weighted avg       0.99      0.99      0.99      7271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   20 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.617; 0.68\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 10']"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((21817, 65), (21817,)) \n",
      " test: ((7273, 65), (7273,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:41:59,674] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:42:07,980] Trial 0 finished with value: 0.9179082161825349 and parameters: {'n_estimators': 150, 'max_depth': 15, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9179082161825349.\n",
      "[I 2024-10-08 00:42:54,924] Trial 1 finished with value: 0.91268282173674 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.9179082161825349.\n",
      "[I 2024-10-08 00:43:01,692] Trial 2 finished with value: 0.904524243844528 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9179082161825349.\n",
      "[I 2024-10-08 00:43:06,070] Trial 3 finished with value: 0.9135996221034602 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.9179082161825349.\n",
      "[I 2024-10-08 00:43:13,163] Trial 4 finished with value: 0.9004906373548252 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.9179082161825349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 116 ms, sys: 62.1 ms, total: 178 ms\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 150, 'max_depth': 15, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.906\n",
      "accuracy: 0.906\n",
      "\n",
      "test data:\n",
      "f1_score: 0.946\n",
      "accuracy: 0.946\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.89      0.98      0.93     14093\n",
      "        Open       0.98      0.76      0.86      1543\n",
      "      Pistol       0.94      0.80      0.86      1544\n",
      "       Thumb       0.97      0.82      0.89      1548\n",
      "          OK       0.89      0.71      0.79      1545\n",
      "        Grab       0.94      0.77      0.84      1544\n",
      "\n",
      "    accuracy                           0.91     21817\n",
      "   macro avg       0.93      0.81      0.86     21817\n",
      "weighted avg       0.91      0.91      0.90     21817\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.93      0.99      0.96      4698\n",
      "        Open       1.00      0.88      0.93       514\n",
      "      Pistol       0.99      0.83      0.90       515\n",
      "       Thumb       0.99      0.89      0.94       516\n",
      "          OK       0.97      0.86      0.91       515\n",
      "        Grab       0.98      0.83      0.90       515\n",
      "\n",
      "    accuracy                           0.95      7273\n",
      "   macro avg       0.98      0.88      0.93      7273\n",
      "weighted avg       0.95      0.95      0.95      7273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.576; 0.62\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((28206, 65), (28206,)) \n",
      " test: ((9402, 65), (9402,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:43:33,475] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:43:40,858] Trial 0 finished with value: 0.9621355484586094 and parameters: {'n_estimators': 150, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 0 with value: 0.9621355484586094.\n",
      "[I 2024-10-08 00:43:51,807] Trial 1 finished with value: 0.9758561303054101 and parameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9758561303054101.\n",
      "[I 2024-10-08 00:43:57,441] Trial 2 finished with value: 0.869850246282016 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9758561303054101.\n",
      "[I 2024-10-08 00:44:04,560] Trial 3 finished with value: 0.9365380169407137 and parameters: {'n_estimators': 150, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 1 with value: 0.9758561303054101.\n",
      "[I 2024-10-08 00:44:12,420] Trial 4 finished with value: 0.8703110820591707 and parameters: {'n_estimators': 175, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9758561303054101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 86.2 ms, sys: 54.8 ms, total: 141 ms\n",
      "Wall time: 38.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.947\n",
      "accuracy: 0.947\n",
      "\n",
      "test data:\n",
      "f1_score: 0.995\n",
      "accuracy: 0.995\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.94      0.99      0.96     16608\n",
      "        Open       0.96      0.90      0.93      2315\n",
      "      Pistol       0.95      0.89      0.92      2321\n",
      "       Thumb       0.94      0.89      0.91      2319\n",
      "          OK       0.96      0.94      0.95      2321\n",
      "        Grab       0.98      0.82      0.89      2322\n",
      "\n",
      "    accuracy                           0.95     28206\n",
      "   macro avg       0.95      0.90      0.93     28206\n",
      "weighted avg       0.95      0.95      0.95     28206\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.99      1.00      1.00      5536\n",
      "        Open       1.00      0.99      0.99       772\n",
      "      Pistol       1.00      0.99      0.99       773\n",
      "       Thumb       1.00      0.98      0.99       773\n",
      "          OK       0.99      0.99      0.99       774\n",
      "        Grab       1.00      0.99      1.00       774\n",
      "\n",
      "    accuracy                           0.99      9402\n",
      "   macro avg       1.00      0.99      0.99      9402\n",
      "weighted avg       0.99      0.99      0.99      9402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.611; 0.601\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((8485, 65), (8485,)) \n",
      " test: ((2829, 65), (2829,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:44:36,730] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:44:59,703] Trial 0 finished with value: 0.8816735415439011 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.8816735415439011.\n",
      "[I 2024-10-08 00:45:01,862] Trial 1 finished with value: 0.8214496169711255 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8816735415439011.\n",
      "[I 2024-10-08 00:45:14,968] Trial 2 finished with value: 0.9255156157925752 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': None}. Best is trial 2 with value: 0.9255156157925752.\n",
      "[I 2024-10-08 00:45:18,160] Trial 3 finished with value: 0.8555097230406601 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 2 with value: 0.9255156157925752.\n",
      "[I 2024-10-08 00:45:30,118] Trial 4 finished with value: 0.8511490866234531 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': None}. Best is trial 2 with value: 0.9255156157925752.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 66.3 ms, sys: 42 ms, total: 108 ms\n",
      "Wall time: 53.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.901\n",
      "accuracy: 0.901\n",
      "\n",
      "test data:\n",
      "f1_score: 0.990\n",
      "accuracy: 0.990\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.94      0.97      0.96      5150\n",
      "        Open       0.82      0.82      0.82       668\n",
      "      Pistol       0.83      0.63      0.71       665\n",
      "       Thumb       0.84      0.88      0.86       665\n",
      "          OK       0.81      0.88      0.84       670\n",
      "        Grab       0.86      0.74      0.80       667\n",
      "\n",
      "    accuracy                           0.90      8485\n",
      "   macro avg       0.85      0.82      0.83      8485\n",
      "weighted avg       0.90      0.90      0.90      8485\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.99      1.00      0.99      1717\n",
      "        Open       1.00      0.98      0.99       223\n",
      "      Pistol       1.00      0.97      0.99       222\n",
      "       Thumb       0.99      0.97      0.98       222\n",
      "          OK       0.98      0.99      0.98       223\n",
      "        Grab       0.99      0.98      0.98       222\n",
      "\n",
      "    accuracy                           0.99      2829\n",
      "   macro avg       0.99      0.98      0.99      2829\n",
      "weighted avg       0.99      0.99      0.99      2829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.577; 0.628\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((8432, 65), (8432,)) \n",
      " test: ((2811, 65), (2811,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:45:56,750] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:45:58,445] Trial 0 finished with value: 0.8815237026427056 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 0 with value: 0.8815237026427056.\n",
      "[I 2024-10-08 00:46:21,512] Trial 1 finished with value: 0.9621685894717894 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': None}. Best is trial 1 with value: 0.9621685894717894.\n",
      "[I 2024-10-08 00:46:34,291] Trial 2 finished with value: 0.9143735396138639 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': None}. Best is trial 1 with value: 0.9621685894717894.\n",
      "[I 2024-10-08 00:46:37,146] Trial 3 finished with value: 0.9141367135888775 and parameters: {'n_estimators': 175, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 1 with value: 0.9621685894717894.\n",
      "[I 2024-10-08 00:46:56,170] Trial 4 finished with value: 0.9385666400167072 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.9621685894717894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 72 ms, sys: 50 ms, total: 122 ms\n",
      "Wall time: 59.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.939\n",
      "accuracy: 0.939\n",
      "\n",
      "test data:\n",
      "f1_score: 0.988\n",
      "accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.96      0.98      0.97      5008\n",
      "        Open       0.96      0.90      0.93       682\n",
      "      Pistol       0.87      0.81      0.84       683\n",
      "       Thumb       0.90      0.91      0.90       686\n",
      "          OK       0.88      0.92      0.90       688\n",
      "        Grab       0.92      0.84      0.88       685\n",
      "\n",
      "    accuracy                           0.94      8432\n",
      "   macro avg       0.92      0.89      0.90      8432\n",
      "weighted avg       0.94      0.94      0.94      8432\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.99      1.00      0.99      1669\n",
      "        Open       1.00      0.98      0.99       228\n",
      "      Pistol       0.99      0.98      0.98       227\n",
      "       Thumb       0.98      0.97      0.98       229\n",
      "          OK       0.98      0.97      0.98       230\n",
      "        Grab       0.99      0.97      0.98       228\n",
      "\n",
      "    accuracy                           0.99      2811\n",
      "   macro avg       0.99      0.98      0.98      2811\n",
      "weighted avg       0.99      0.99      0.99      2811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.606; 0.584\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((12627, 65), (12627,)) \n",
      " test: ((4210, 65), (4210,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:47:39,509] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:47:54,786] Trial 0 finished with value: 0.9086874720726229 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': None}. Best is trial 0 with value: 0.9086874720726229.\n",
      "[I 2024-10-08 00:48:20,655] Trial 1 finished with value: 0.9308627736882951 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.9308627736882951.\n",
      "[I 2024-10-08 00:48:23,020] Trial 2 finished with value: 0.9156563580348533 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9308627736882951.\n",
      "[I 2024-10-08 00:48:55,753] Trial 3 finished with value: 0.9461470802662214 and parameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': None}. Best is trial 3 with value: 0.9461470802662214.\n",
      "[I 2024-10-08 00:49:10,083] Trial 4 finished with value: 0.9496317897823037 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': None}. Best is trial 4 with value: 0.9496317897823037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 102 ms, sys: 71.3 ms, total: 173 ms\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.920\n",
      "accuracy: 0.920\n",
      "\n",
      "test data:\n",
      "f1_score: 0.987\n",
      "accuracy: 0.987\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.95      0.97      0.96      7521\n",
      "        Open       0.91      0.90      0.91      1017\n",
      "      Pistol       0.86      0.82      0.84      1026\n",
      "       Thumb       0.87      0.88      0.87      1021\n",
      "          OK       0.82      0.83      0.82      1017\n",
      "        Grab       0.91      0.84      0.87      1025\n",
      "\n",
      "    accuracy                           0.92     12627\n",
      "   macro avg       0.89      0.87      0.88     12627\n",
      "weighted avg       0.92      0.92      0.92     12627\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.98      1.00      0.99      2508\n",
      "        Open       0.99      0.97      0.98       339\n",
      "      Pistol       0.99      0.98      0.99       342\n",
      "       Thumb       0.98      0.96      0.97       340\n",
      "          OK       1.00      0.97      0.99       339\n",
      "        Grab       0.99      0.98      0.99       342\n",
      "\n",
      "    accuracy                           0.99      4210\n",
      "   macro avg       0.99      0.98      0.98      4210\n",
      "weighted avg       0.99      0.99      0.99      4210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.576; 0.632\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((19986, 65), (19986,)) \n",
      " test: ((6662, 65), (6662,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:49:39,952] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:49:58,019] Trial 0 finished with value: 0.9438108846767641 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.9438108846767641.\n",
      "[I 2024-10-08 00:50:36,527] Trial 1 finished with value: 0.9703791475422475 and parameters: {'n_estimators': 150, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': None}. Best is trial 1 with value: 0.9703791475422475.\n",
      "[I 2024-10-08 00:51:00,624] Trial 2 finished with value: 0.9794855521330843 and parameters: {'n_estimators': 125, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': None}. Best is trial 2 with value: 0.9794855521330843.\n",
      "[I 2024-10-08 00:51:05,044] Trial 3 finished with value: 0.9312017655062208 and parameters: {'n_estimators': 150, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 2 with value: 0.9794855521330843.\n",
      "[I 2024-10-08 00:51:09,524] Trial 4 finished with value: 0.9085360418512984 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9794855521330843.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 100 ms, sys: 68.4 ms, total: 169 ms\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 125, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.964\n",
      "accuracy: 0.964\n",
      "\n",
      "test data:\n",
      "f1_score: 0.993\n",
      "accuracy: 0.993\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.97      0.99      0.98     11827\n",
      "        Open       0.97      0.92      0.95      1635\n",
      "      Pistol       0.93      0.91      0.92      1634\n",
      "       Thumb       0.96      0.94      0.95      1633\n",
      "          OK       0.94      0.96      0.95      1627\n",
      "        Grab       0.95      0.93      0.94      1630\n",
      "\n",
      "    accuracy                           0.96     19986\n",
      "   macro avg       0.95      0.94      0.95     19986\n",
      "weighted avg       0.96      0.96      0.96     19986\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.99      1.00      0.99      3943\n",
      "        Open       0.99      0.99      0.99       545\n",
      "      Pistol       0.99      0.99      0.99       544\n",
      "       Thumb       1.00      0.99      0.99       544\n",
      "          OK       0.98      0.99      0.99       543\n",
      "        Grab       1.00      0.99      1.00       543\n",
      "\n",
      "    accuracy                           0.99      6662\n",
      "   macro avg       0.99      0.99      0.99      6662\n",
      "weighted avg       0.99      0.99      0.99      6662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   20 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.596; 0.582\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 10']"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((5223, 65), (5223,)) \n",
      " test: ((1741, 65), (1741,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:51:55,473] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:52:05,303] Trial 0 finished with value: 0.8022218555793874 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.8022218555793874.\n",
      "[I 2024-10-08 00:52:11,399] Trial 1 finished with value: 0.6613057984564337 and parameters: {'n_estimators': 175, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.8022218555793874.\n",
      "[I 2024-10-08 00:52:12,115] Trial 2 finished with value: 0.6626473445892683 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.8022218555793874.\n",
      "[I 2024-10-08 00:52:13,235] Trial 3 finished with value: 0.707066124035271 and parameters: {'n_estimators': 150, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.8022218555793874.\n",
      "[I 2024-10-08 00:52:14,477] Trial 4 finished with value: 0.6643698326275459 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 0 with value: 0.8022218555793874.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.9 ms, sys: 24.2 ms, total: 68.1 ms\n",
      "Wall time: 19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.702\n",
      "accuracy: 0.702\n",
      "\n",
      "test data:\n",
      "f1_score: 0.953\n",
      "accuracy: 0.953\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.68      0.96      0.80      3138\n",
      "        Open       0.83      0.26      0.40       417\n",
      "      Pistol       0.82      0.38      0.52       414\n",
      "       Thumb       0.84      0.38      0.52       418\n",
      "          OK       0.81      0.28      0.42       419\n",
      "        Grab       0.81      0.28      0.42       417\n",
      "\n",
      "    accuracy                           0.70      5223\n",
      "   macro avg       0.80      0.42      0.51      5223\n",
      "weighted avg       0.74      0.70      0.66      5223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.93      1.00      0.96      1046\n",
      "        Open       1.00      0.89      0.94       139\n",
      "      Pistol       1.00      0.90      0.95       138\n",
      "       Thumb       1.00      0.85      0.92       140\n",
      "          OK       1.00      0.88      0.94       139\n",
      "        Grab       0.99      0.88      0.94       139\n",
      "\n",
      "    accuracy                           0.95      1741\n",
      "   macro avg       0.99      0.90      0.94      1741\n",
      "weighted avg       0.96      0.95      0.95      1741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   12 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.653; 0.579\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 6']"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((8376, 65), (8376,)) \n",
      " test: ((2793, 65), (2793,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:52:35,779] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:52:47,527] Trial 0 finished with value: 0.8724927866633421 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.8724927866633421.\n",
      "[I 2024-10-08 00:52:56,460] Trial 1 finished with value: 0.8206783742385924 and parameters: {'n_estimators': 175, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.8724927866633421.\n",
      "[I 2024-10-08 00:53:05,213] Trial 2 finished with value: 0.8678361414882627 and parameters: {'n_estimators': 150, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.8724927866633421.\n",
      "[I 2024-10-08 00:53:06,529] Trial 3 finished with value: 0.789278951305525 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 0 with value: 0.8724927866633421.\n",
      "[I 2024-10-08 00:53:08,607] Trial 4 finished with value: 0.8476603854237169 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8724927866633421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.8 ms, sys: 30 ms, total: 79.8 ms\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.820\n",
      "accuracy: 0.820\n",
      "\n",
      "test data:\n",
      "f1_score: 0.952\n",
      "accuracy: 0.952\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.83      0.90      0.86      4950\n",
      "        Open       0.87      0.74      0.80       685\n",
      "      Pistol       0.77      0.60      0.67       685\n",
      "       Thumb       0.75      0.73      0.74       685\n",
      "          OK       0.80      0.76      0.78       686\n",
      "        Grab       0.81      0.71      0.76       685\n",
      "\n",
      "    accuracy                           0.82      8376\n",
      "   macro avg       0.81      0.74      0.77      8376\n",
      "weighted avg       0.82      0.82      0.82      8376\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.95      0.97      0.96      1650\n",
      "        Open       0.96      0.93      0.95       228\n",
      "      Pistol       0.95      0.92      0.93       229\n",
      "       Thumb       0.93      0.92      0.93       229\n",
      "          OK       0.96      0.92      0.94       228\n",
      "        Grab       0.97      0.91      0.94       229\n",
      "\n",
      "    accuracy                           0.95      2793\n",
      "   macro avg       0.95      0.93      0.94      2793\n",
      "weighted avg       0.95      0.95      0.95      2793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.604; 0.578\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((8376, 65), (8376,)) \n",
      " test: ((2792, 65), (2792,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:53:33,033] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:53:34,243] Trial 0 finished with value: 0.7919053182773482 and parameters: {'n_estimators': 175, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.7919053182773482.\n",
      "[I 2024-10-08 00:53:35,671] Trial 1 finished with value: 0.8809683325615361 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 1 with value: 0.8809683325615361.\n",
      "[I 2024-10-08 00:53:40,965] Trial 2 finished with value: 0.9547523955401989 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': None}. Best is trial 2 with value: 0.9547523955401989.\n",
      "[I 2024-10-08 00:53:51,880] Trial 3 finished with value: 0.9567818188294803 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': None}. Best is trial 3 with value: 0.9567818188294803.\n",
      "[I 2024-10-08 00:53:57,182] Trial 4 finished with value: 0.9250233320272148 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': None}. Best is trial 3 with value: 0.9567818188294803.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.6 ms, sys: 26.3 ms, total: 72.9 ms\n",
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.935\n",
      "accuracy: 0.935\n",
      "\n",
      "test data:\n",
      "f1_score: 0.977\n",
      "accuracy: 0.977\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.95      0.97      0.96      4953\n",
      "        Open       0.97      0.88      0.92       686\n",
      "      Pistol       0.90      0.86      0.88       685\n",
      "       Thumb       0.91      0.87      0.89       684\n",
      "          OK       0.89      0.88      0.89       685\n",
      "        Grab       0.90      0.92      0.91       683\n",
      "\n",
      "    accuracy                           0.94      8376\n",
      "   macro avg       0.92      0.90      0.91      8376\n",
      "weighted avg       0.94      0.94      0.93      8376\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.97      0.99      0.98      1651\n",
      "        Open       0.99      0.97      0.98       229\n",
      "      Pistol       0.98      0.93      0.96       229\n",
      "       Thumb       0.99      0.94      0.96       228\n",
      "          OK       1.00      0.97      0.98       228\n",
      "        Grab       0.97      0.98      0.97       227\n",
      "\n",
      "    accuracy                           0.98      2792\n",
      "   macro avg       0.98      0.96      0.97      2792\n",
      "weighted avg       0.98      0.98      0.98      2792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.604; 0.579\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((8376, 65), (8376,)) \n",
      " test: ((2792, 65), (2792,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:54:19,968] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:54:21,153] Trial 0 finished with value: 0.8223493036013252 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8223493036013252.\n",
      "[I 2024-10-08 00:54:22,766] Trial 1 finished with value: 0.9361271684536744 and parameters: {'n_estimators': 175, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9361271684536744.\n",
      "[I 2024-10-08 00:54:27,979] Trial 2 finished with value: 0.878701171944573 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.9361271684536744.\n",
      "[I 2024-10-08 00:54:29,914] Trial 3 finished with value: 0.9509309300751612 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 3 with value: 0.9509309300751612.\n",
      "[I 2024-10-08 00:54:38,361] Trial 4 finished with value: 0.9578548071100345 and parameters: {'n_estimators': 175, 'max_depth': 15, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': None}. Best is trial 4 with value: 0.9578548071100345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47 ms, sys: 30.4 ms, total: 77.4 ms\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 175, 'max_depth': 15, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.928\n",
      "accuracy: 0.928\n",
      "\n",
      "test data:\n",
      "f1_score: 0.975\n",
      "accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.95      0.97      0.96      4952\n",
      "        Open       0.93      0.91      0.92       685\n",
      "      Pistol       0.90      0.82      0.86       686\n",
      "       Thumb       0.91      0.86      0.88       683\n",
      "          OK       0.85      0.92      0.89       684\n",
      "        Grab       0.92      0.83      0.87       686\n",
      "\n",
      "    accuracy                           0.93      8376\n",
      "   macro avg       0.91      0.89      0.90      8376\n",
      "weighted avg       0.93      0.93      0.93      8376\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.98      0.98      0.98      1651\n",
      "        Open       0.98      0.98      0.98       228\n",
      "      Pistol       0.97      0.96      0.96       229\n",
      "       Thumb       0.97      0.93      0.95       228\n",
      "          OK       0.98      0.99      0.98       228\n",
      "        Grab       0.97      0.96      0.96       228\n",
      "\n",
      "    accuracy                           0.97      2792\n",
      "   macro avg       0.97      0.96      0.97      2792\n",
      "weighted avg       0.97      0.97      0.97      2792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.605; 0.579\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((8376, 65), (8376,)) \n",
      " test: ((2793, 65), (2793,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:54:57,381] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:55:01,801] Trial 0 finished with value: 0.9582137997364015 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 0 with value: 0.9582137997364015.\n",
      "[I 2024-10-08 00:55:02,882] Trial 1 finished with value: 0.8431228582623873 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.9582137997364015.\n",
      "[I 2024-10-08 00:55:03,767] Trial 2 finished with value: 0.9389915577245039 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.9582137997364015.\n",
      "[I 2024-10-08 00:55:05,017] Trial 3 finished with value: 0.8464657143874896 and parameters: {'n_estimators': 175, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 0 with value: 0.9582137997364015.\n",
      "[I 2024-10-08 00:55:15,281] Trial 4 finished with value: 0.961675845118085 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': None}. Best is trial 4 with value: 0.961675845118085.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.4 ms, sys: 25.2 ms, total: 69.5 ms\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.938\n",
      "accuracy: 0.938\n",
      "\n",
      "test data:\n",
      "f1_score: 0.977\n",
      "accuracy: 0.977\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.95      0.97      0.96      4949\n",
      "        Open       0.94      0.92      0.93       685\n",
      "      Pistol       0.90      0.87      0.88       685\n",
      "       Thumb       0.93      0.83      0.88       685\n",
      "          OK       0.89      0.93      0.91       687\n",
      "        Grab       0.95      0.88      0.91       685\n",
      "\n",
      "    accuracy                           0.94      8376\n",
      "   macro avg       0.93      0.90      0.91      8376\n",
      "weighted avg       0.94      0.94      0.94      8376\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.98      0.99      0.98      1651\n",
      "        Open       0.97      0.97      0.97       228\n",
      "      Pistol       0.99      0.96      0.98       228\n",
      "       Thumb       0.98      0.96      0.97       228\n",
      "          OK       0.96      0.96      0.96       229\n",
      "        Grab       0.97      0.97      0.97       229\n",
      "\n",
      "    accuracy                           0.98      2793\n",
      "   macro avg       0.98      0.97      0.97      2793\n",
      "weighted avg       0.98      0.98      0.98      2793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.604; 0.58\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((8379, 65), (8379,)) \n",
      " test: ((2794, 65), (2794,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:55:37,671] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:55:43,967] Trial 0 finished with value: 0.9585863285006946 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': None}. Best is trial 0 with value: 0.9585863285006946.\n",
      "[I 2024-10-08 00:55:45,241] Trial 1 finished with value: 0.8672854344031631 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 0 with value: 0.9585863285006946.\n",
      "[I 2024-10-08 00:55:47,428] Trial 2 finished with value: 0.9657474441634312 and parameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9657474441634312.\n",
      "[I 2024-10-08 00:55:48,637] Trial 3 finished with value: 0.9601377123926904 and parameters: {'n_estimators': 125, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'log2'}. Best is trial 2 with value: 0.9657474441634312.\n",
      "[I 2024-10-08 00:55:55,623] Trial 4 finished with value: 0.9255253090157802 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': None}. Best is trial 2 with value: 0.9657474441634312.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56 ms, sys: 29.6 ms, total: 85.6 ms\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 4, 'criterion': 'entropy', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.936\n",
      "accuracy: 0.936\n",
      "\n",
      "test data:\n",
      "f1_score: 0.975\n",
      "accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.93      0.98      0.95      4950\n",
      "        Open       0.97      0.79      0.87       687\n",
      "      Pistol       0.94      0.93      0.94       686\n",
      "       Thumb       0.96      0.82      0.88       684\n",
      "          OK       0.96      0.93      0.94       685\n",
      "        Grab       0.95      0.90      0.92       687\n",
      "\n",
      "    accuracy                           0.94      8379\n",
      "   macro avg       0.95      0.89      0.92      8379\n",
      "weighted avg       0.94      0.94      0.94      8379\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.97      0.99      0.98      1651\n",
      "        Open       1.00      0.95      0.98       229\n",
      "      Pistol       0.96      0.96      0.96       228\n",
      "       Thumb       0.99      0.93      0.96       228\n",
      "          OK       0.97      0.97      0.97       229\n",
      "        Grab       0.98      0.96      0.97       229\n",
      "\n",
      "    accuracy                           0.97      2794\n",
      "   macro avg       0.98      0.96      0.97      2794\n",
      "weighted avg       0.98      0.97      0.97      2794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.603; 0.586\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((8386, 65), (8386,)) \n",
      " test: ((2796, 65), (2796,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:56:03,936] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:56:09,504] Trial 0 finished with value: 0.9255915587955391 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': None}. Best is trial 0 with value: 0.9255915587955391.\n",
      "[I 2024-10-08 00:56:11,372] Trial 1 finished with value: 0.9585022917506217 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9585022917506217.\n",
      "[I 2024-10-08 00:56:17,234] Trial 2 finished with value: 0.9577870836096298 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': None}. Best is trial 1 with value: 0.9585022917506217.\n",
      "[I 2024-10-08 00:56:23,264] Trial 3 finished with value: 0.9425241452932227 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.9585022917506217.\n",
      "[I 2024-10-08 00:56:24,167] Trial 4 finished with value: 0.8595280180639273 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_leaf': 4, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9585022917506217.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.4 ms, sys: 26.1 ms, total: 72.5 ms\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.909\n",
      "accuracy: 0.909\n",
      "\n",
      "test data:\n",
      "f1_score: 0.970\n",
      "accuracy: 0.970\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.90      0.98      0.94      4955\n",
      "        Open       0.96      0.73      0.83       685\n",
      "      Pistol       0.88      0.73      0.80       686\n",
      "       Thumb       0.93      0.83      0.88       687\n",
      "          OK       0.90      0.94      0.92       687\n",
      "        Grab       0.93      0.83      0.88       686\n",
      "\n",
      "    accuracy                           0.91      8386\n",
      "   macro avg       0.92      0.84      0.87      8386\n",
      "weighted avg       0.91      0.91      0.91      8386\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.97      0.99      0.98      1652\n",
      "        Open       1.00      0.92      0.96       228\n",
      "      Pistol       0.97      0.94      0.96       229\n",
      "       Thumb       0.95      0.96      0.95       229\n",
      "          OK       0.97      0.98      0.97       229\n",
      "        Grab       0.98      0.92      0.95       229\n",
      "\n",
      "    accuracy                           0.97      2796\n",
      "   macro avg       0.97      0.95      0.96      2796\n",
      "weighted avg       0.97      0.97      0.97      2796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Palm File 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, current_file, palm_file = read_pilot(data=data_meta,\n",
    "                                               file_number=next(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocol File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures_protocol = pd.read_csv(f'{\"./data_csv/\" + current_file}.protocol.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT\n",
    "le.fit(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")\n",
    "\n",
    "#TRANSFORM\n",
    "gestures_protocol['gesture'] = le.transform(\n",
    "    gestures_protocol[[\n",
    "        \"Thumb\", \"Index\", \"Middle\", \"Ring\", \"Pinky\",\n",
    "        'Thumb_stretch', 'Index_stretch', 'Middle_stretch', 'Ring_stretch', 'Pinky_stretch'\n",
    "    ]]\n",
    "    .apply(lambda row: str(tuple(row)), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the gestures\n",
    "MAIN_GESTURES = ['Neutral', 'Open', 'Pistol', 'Thumb', 'OK', 'Grab']\n",
    "MAIN_GESTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock the predictive feature\n",
    "y_cmd = np.array([gestures_protocol['gesture'].loc[s] for s in gestures['SYNC'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the time interval shift function\n",
    "y, summary = get_naive_centering(gestures, y_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Оптимальные свдиги для концевых выборок:   1 и 1\\n',\n",
       " 'Accuracy/correlation на концевых выборках: 0.603; 0.581\\n',\n",
       " 'Размер оптимального сдвига (как среднего): 1']"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the features\n",
    "X = gestures[gestures.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ((8380, 65), (8380,)) \n",
      " test: ((2794, 65), (2794,))\n"
     ]
    }
   ],
   "source": [
    "#use stratified samplifing to split the data evenly\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, \n",
    "    stratify=y, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "#find the dimensions\n",
    "print(f'train: {X_train.shape, y_train.shape} \\n test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 00:56:33,423] A new study created in memory with name: RandomForest\n",
      "[I 2024-10-08 00:56:35,129] Trial 0 finished with value: 0.95381861575179 and parameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 0 with value: 0.95381861575179.\n",
      "[I 2024-10-08 00:56:37,273] Trial 1 finished with value: 0.966109785202864 and parameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'sqrt'}. Best is trial 1 with value: 0.966109785202864.\n",
      "[I 2024-10-08 00:56:45,752] Trial 2 finished with value: 0.9594272076372314 and parameters: {'n_estimators': 150, 'max_depth': 20, 'min_samples_leaf': 5, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.966109785202864.\n",
      "[I 2024-10-08 00:56:52,945] Trial 3 finished with value: 0.9113365155131264 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'entropy', 'max_features': None}. Best is trial 1 with value: 0.966109785202864.\n",
      "[I 2024-10-08 00:56:53,856] Trial 4 finished with value: 0.79236276849642 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'log2'}. Best is trial 1 with value: 0.966109785202864.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57 ms, sys: 31.9 ms, total: 88.9 ms\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#begin hyperparameters selection\n",
    "#create review object\n",
    "study_optuna_rf = optuna.create_study(study_name='RandomForest',\n",
    "                                       direction='maximize')\n",
    "\n",
    "#search for the best combination\n",
    "study_optuna_rf.optimize(optuna_rf,\n",
    "                         n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hyperparameters: {'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 3, 'criterion': 'gini', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#find the best hyperparameters\n",
    "print(f'Random Forest Hyperparameters: {study_optuna_rf.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the metrics for test data\n",
    "model_opt_rf = ensemble.RandomForestClassifier(**study_optuna_rf.best_params,\n",
    "                                               random_state=42,\n",
    "                                               )\n",
    "\n",
    "#set the start_time\n",
    "start_time = time.time()\n",
    "\n",
    "#model learning\n",
    "model_opt_rf.fit(X_train, y_train)\n",
    "model_opt_rf.fit(X_test, y_test)\n",
    "\n",
    "#calculate the model learning time\n",
    "model_opt_rf_time = round(time.time() - start_time, 2)\n",
    "\n",
    "#make a prediction\n",
    "y_train_pred_rf = model_opt_rf.predict(X_train)\n",
    "y_test_pred_rf = model_opt_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "f1_score: 0.931\n",
      "accuracy: 0.931\n",
      "\n",
      "test data:\n",
      "f1_score: 0.977\n",
      "accuracy: 0.977\n"
     ]
    }
   ],
   "source": [
    "#display the metrics\n",
    "print('train data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_train, y_train):.3f}')\n",
    "print()\n",
    "print('test data:')\n",
    "print(f'f1_score: {metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"):.3f}')\n",
    "print(f'accuracy: {model_opt_rf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.92      0.98      0.95      4953\n",
      "        Open       0.97      0.86      0.91       686\n",
      "      Pistol       0.95      0.83      0.89       685\n",
      "       Thumb       0.93      0.82      0.87       684\n",
      "          OK       0.95      0.89      0.92       686\n",
      "        Grab       0.95      0.90      0.93       686\n",
      "\n",
      "    accuracy                           0.93      8380\n",
      "   macro avg       0.95      0.88      0.91      8380\n",
      "weighted avg       0.93      0.93      0.93      8380\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.97      0.99      0.98      1651\n",
      "        Open       0.99      0.96      0.97       229\n",
      "      Pistol       0.98      0.95      0.97       229\n",
      "       Thumb       0.99      0.96      0.98       228\n",
      "          OK       0.97      0.97      0.97       228\n",
      "        Grab       0.98      0.97      0.97       229\n",
      "\n",
      "    accuracy                           0.98      2794\n",
      "   macro avg       0.98      0.97      0.97      2794\n",
      "weighted avg       0.98      0.98      0.98      2794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,\n",
    "                            y_train_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            y_test_pred_rf,\n",
    "                            target_names=MAIN_GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the classification report into a dataframe\n",
    "report_rf = classification_report(y_test,\n",
    "                                  y_test_pred_rf,\n",
    "                                  target_names=MAIN_GESTURES,\n",
    "                                  output_dict=True)\n",
    "\n",
    "test_rf = pd.DataFrame(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model results to the ordered dict\n",
    "review['palm_file'].append(current_file)\n",
    "review['model_name'].append(model_opt_rf.__class__.__name__)\n",
    "review['learning_time'].append(model_opt_rf_time)\n",
    "review['hyperparameters'].append(study_optuna_rf.best_params)\n",
    "review['F1-Score, train'].append(round(metrics.f1_score(y_train, y_train_pred_rf, average=\"micro\"), 3))\n",
    "review['F1-Score, test'].append(round(metrics.f1_score(y_test, y_test_pred_rf, average=\"micro\"), 3))\n",
    "\n",
    "review['F1-Score: Neutral'].append(test_rf.loc['f1-score'].iloc[0].round(3))\n",
    "review['F1-Score: Open'].append(test_rf.loc['f1-score'].iloc[1].round(3))\n",
    "review['F1-Score: Pistol'].append(test_rf.loc['f1-score'].iloc[2].round(3))\n",
    "review['F1-Score: Thumb'].append(test_rf.loc['f1-score'].iloc[3].round(3))\n",
    "review['F1-Score: OK'].append(test_rf.loc['f1-score'].iloc[4].round(3))\n",
    "review['F1-Score: Grab'].append(test_rf.loc['f1-score'].iloc[5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palm_file</th>\n",
       "      <th>model_name</th>\n",
       "      <th>learning_time</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>F1-Score, train</th>\n",
       "      <th>F1-Score, test</th>\n",
       "      <th>F1-Score: Neutral</th>\n",
       "      <th>F1-Score: Open</th>\n",
       "      <th>F1-Score: Pistol</th>\n",
       "      <th>F1-Score: Thumb</th>\n",
       "      <th>F1-Score: OK</th>\n",
       "      <th>F1-Score: Grab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-15_16-16-08.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>9.69</td>\n",
       "      <td>{'n_estimators': 125, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-15_17-12-24.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>90.39</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-05_16-12-38.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>8.59</td>\n",
       "      <td>{'n_estimators': 125, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-05_17-53-01.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>5.87</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 15, 'min_sa...</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-20_14-43-11.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>10.16</td>\n",
       "      <td>{'n_estimators': 175, 'max_depth': 15, 'min_sa...</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-06-20_13-30-15.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>8.15</td>\n",
       "      <td>{'n_estimators': 175, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-06-20_12-34-17.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>11.83</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-09-30_08-06-44.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>6.21</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-09-29_11-03-50.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>3.84</td>\n",
       "      <td>{'n_estimators': 125, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-09-29_09-20-47.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2.92</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-09-13_22-14-05.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2.19</td>\n",
       "      <td>{'n_estimators': 125, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-09-12_14-59-23.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>3.16</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-09-12_12-55-22.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>9.84</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 15, 'min_sa...</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-05-31_17-14-41.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>54.95</td>\n",
       "      <td>{'n_estimators': 175, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-05-31_15-46-37.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>74.01</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-05-22_20-22-01.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>5.40</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-05-22_17-04-29.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>84.11</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-05-19_12-04-02.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>13.38</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 15, 'min_sa...</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-04-18_19-08-47 gestures train.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>17.77</td>\n",
       "      <td>{'n_estimators': 175, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-05-07_16-54-27.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>21.34</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 15, 'min_sa...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-05-07_15-19-05.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>37.60</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-05-12_19-17-00.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>23.67</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 15, 'min_sa...</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-05-05_17-57-30.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>40.42</td>\n",
       "      <td>{'n_estimators': 125, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-10-25_11-08-46.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>15.40</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 15, 'min_sa...</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>patched_2023-10-25_09-44-02.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>19.15</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023-10-25_08-52-30.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>16.86</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 15, 'min_sa...</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023-10-23_16-23-02.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>13.58</td>\n",
       "      <td>{'n_estimators': 175, 'max_depth': 15, 'min_sa...</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-10-23_14-07-13.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>16.50</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 15, 'min_sa...</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023-10-23_10-11-45.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2.66</td>\n",
       "      <td>{'n_estimators': 175, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-10-18_08-05-29.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2.99</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 15, 'min_sa...</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023-10-18_11-16-21.palm</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2.83</td>\n",
       "      <td>{'n_estimators': 175, 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  palm_file              model_name  \\\n",
       "0                  2023-05-15_16-16-08.palm  RandomForestClassifier   \n",
       "1                  2023-05-15_17-12-24.palm  RandomForestClassifier   \n",
       "2                  2023-06-05_16-12-38.palm  RandomForestClassifier   \n",
       "3                  2023-06-05_17-53-01.palm  RandomForestClassifier   \n",
       "4                  2023-06-20_14-43-11.palm  RandomForestClassifier   \n",
       "5                  2023-06-20_13-30-15.palm  RandomForestClassifier   \n",
       "6                  2023-06-20_12-34-17.palm  RandomForestClassifier   \n",
       "7                  2023-09-30_08-06-44.palm  RandomForestClassifier   \n",
       "8                  2023-09-29_11-03-50.palm  RandomForestClassifier   \n",
       "9                  2023-09-29_09-20-47.palm  RandomForestClassifier   \n",
       "10                 2023-09-13_22-14-05.palm  RandomForestClassifier   \n",
       "11                 2023-09-12_14-59-23.palm  RandomForestClassifier   \n",
       "12                 2023-09-12_12-55-22.palm  RandomForestClassifier   \n",
       "13                 2023-05-31_17-14-41.palm  RandomForestClassifier   \n",
       "14                 2023-05-31_15-46-37.palm  RandomForestClassifier   \n",
       "15                 2023-05-22_20-22-01.palm  RandomForestClassifier   \n",
       "16                 2023-05-22_17-04-29.palm  RandomForestClassifier   \n",
       "17                 2023-05-19_12-04-02.palm  RandomForestClassifier   \n",
       "18  2023-04-18_19-08-47 gestures train.palm  RandomForestClassifier   \n",
       "19                 2023-05-07_16-54-27.palm  RandomForestClassifier   \n",
       "20                 2023-05-07_15-19-05.palm  RandomForestClassifier   \n",
       "21                 2023-05-12_19-17-00.palm  RandomForestClassifier   \n",
       "22                 2023-05-05_17-57-30.palm  RandomForestClassifier   \n",
       "23                 2023-10-25_11-08-46.palm  RandomForestClassifier   \n",
       "24         patched_2023-10-25_09-44-02.palm  RandomForestClassifier   \n",
       "25                 2023-10-25_08-52-30.palm  RandomForestClassifier   \n",
       "26                 2023-10-23_16-23-02.palm  RandomForestClassifier   \n",
       "27                 2023-10-23_14-07-13.palm  RandomForestClassifier   \n",
       "28                 2023-10-23_10-11-45.palm  RandomForestClassifier   \n",
       "29                 2023-10-18_08-05-29.palm  RandomForestClassifier   \n",
       "30                 2023-10-18_11-16-21.palm  RandomForestClassifier   \n",
       "\n",
       "    learning_time                                    hyperparameters  \\\n",
       "0            9.69  {'n_estimators': 125, 'max_depth': 20, 'min_sa...   \n",
       "1           90.39  {'n_estimators': 150, 'max_depth': 20, 'min_sa...   \n",
       "2            8.59  {'n_estimators': 125, 'max_depth': 20, 'min_sa...   \n",
       "3            5.87  {'n_estimators': 100, 'max_depth': 15, 'min_sa...   \n",
       "4           10.16  {'n_estimators': 175, 'max_depth': 15, 'min_sa...   \n",
       "5            8.15  {'n_estimators': 175, 'max_depth': 20, 'min_sa...   \n",
       "6           11.83  {'n_estimators': 200, 'max_depth': 20, 'min_sa...   \n",
       "7            6.21  {'n_estimators': 200, 'max_depth': 20, 'min_sa...   \n",
       "8            3.84  {'n_estimators': 125, 'max_depth': 20, 'min_sa...   \n",
       "9            2.92  {'n_estimators': 100, 'max_depth': 20, 'min_sa...   \n",
       "10           2.19  {'n_estimators': 125, 'max_depth': 20, 'min_sa...   \n",
       "11           3.16  {'n_estimators': 200, 'max_depth': 20, 'min_sa...   \n",
       "12           9.84  {'n_estimators': 100, 'max_depth': 15, 'min_sa...   \n",
       "13          54.95  {'n_estimators': 175, 'max_depth': 20, 'min_sa...   \n",
       "14          74.01  {'n_estimators': 200, 'max_depth': 20, 'min_sa...   \n",
       "15           5.40  {'n_estimators': 100, 'max_depth': 20, 'min_sa...   \n",
       "16          84.11  {'n_estimators': 150, 'max_depth': 20, 'min_sa...   \n",
       "17          13.38  {'n_estimators': 150, 'max_depth': 15, 'min_sa...   \n",
       "18          17.77  {'n_estimators': 175, 'max_depth': 20, 'min_sa...   \n",
       "19          21.34  {'n_estimators': 100, 'max_depth': 15, 'min_sa...   \n",
       "20          37.60  {'n_estimators': 200, 'max_depth': 20, 'min_sa...   \n",
       "21          23.67  {'n_estimators': 100, 'max_depth': 15, 'min_sa...   \n",
       "22          40.42  {'n_estimators': 125, 'max_depth': 20, 'min_sa...   \n",
       "23          15.40  {'n_estimators': 200, 'max_depth': 15, 'min_sa...   \n",
       "24          19.15  {'n_estimators': 200, 'max_depth': 20, 'min_sa...   \n",
       "25          16.86  {'n_estimators': 200, 'max_depth': 15, 'min_sa...   \n",
       "26          13.58  {'n_estimators': 175, 'max_depth': 15, 'min_sa...   \n",
       "27          16.50  {'n_estimators': 200, 'max_depth': 15, 'min_sa...   \n",
       "28           2.66  {'n_estimators': 175, 'max_depth': 20, 'min_sa...   \n",
       "29           2.99  {'n_estimators': 200, 'max_depth': 15, 'min_sa...   \n",
       "30           2.83  {'n_estimators': 175, 'max_depth': 20, 'min_sa...   \n",
       "\n",
       "    F1-Score, train  F1-Score, test  F1-Score: Neutral  F1-Score: Open  \\\n",
       "0             0.947           0.987              0.992           0.980   \n",
       "1             0.827           0.966              0.975           0.983   \n",
       "2             0.929           0.983              0.987           0.985   \n",
       "3             0.919           0.974              0.981           0.971   \n",
       "4             0.920           0.971              0.980           0.969   \n",
       "5             0.932           0.985              0.987           0.991   \n",
       "6             0.927           0.979              0.984           0.983   \n",
       "7             0.938           0.986              0.988           0.985   \n",
       "8             0.931           0.979              0.983           0.971   \n",
       "9             0.929           0.982              0.985           0.978   \n",
       "10            0.910           0.988              0.990           0.987   \n",
       "11            0.928           0.989              0.991           0.991   \n",
       "12            0.962           0.978              0.982           0.973   \n",
       "13            0.887           0.969              0.977           0.948   \n",
       "14            0.929           0.990              0.992           0.985   \n",
       "15            0.918           0.978              0.983           0.955   \n",
       "16            0.918           0.987              0.991           0.985   \n",
       "17            0.906           0.946              0.960           0.935   \n",
       "18            0.947           0.995              0.996           0.995   \n",
       "19            0.901           0.990              0.993           0.989   \n",
       "20            0.939           0.988              0.992           0.991   \n",
       "21            0.920           0.987              0.990           0.982   \n",
       "22            0.964           0.993              0.994           0.992   \n",
       "23            0.702           0.953              0.963           0.943   \n",
       "24            0.820           0.952              0.962           0.947   \n",
       "25            0.935           0.977              0.981           0.978   \n",
       "26            0.928           0.975              0.980           0.980   \n",
       "27            0.938           0.977              0.981           0.974   \n",
       "28            0.936           0.975              0.979           0.975   \n",
       "29            0.909           0.970              0.979           0.957   \n",
       "30            0.931           0.977              0.981           0.973   \n",
       "\n",
       "    F1-Score: Pistol  F1-Score: Thumb  F1-Score: OK  F1-Score: Grab  \n",
       "0              0.983            0.971         0.984           0.979  \n",
       "1              0.945            0.915         0.938           0.958  \n",
       "2              0.977            0.972         0.976           0.974  \n",
       "3              0.963            0.970         0.954           0.962  \n",
       "4              0.946            0.959         0.948           0.963  \n",
       "5              0.980            0.972         0.981           0.980  \n",
       "6              0.967            0.971         0.971           0.975  \n",
       "7              0.971            0.980         0.987           0.987  \n",
       "8              0.957            0.985         0.976           0.971  \n",
       "9              0.969            0.980         0.984           0.978  \n",
       "10             0.987            0.982         0.982           0.987  \n",
       "11             0.987            0.983         0.978           0.991  \n",
       "12             0.978            0.969         0.959           0.973  \n",
       "13             0.952            0.955         0.949           0.956  \n",
       "14             0.984            0.988         0.986           0.984  \n",
       "15             0.959            0.972         0.981           0.973  \n",
       "16             0.975            0.980         0.982           0.984  \n",
       "17             0.904            0.939         0.915           0.900  \n",
       "18             0.994            0.988         0.993           0.996  \n",
       "19             0.986            0.982         0.984           0.984  \n",
       "20             0.985            0.978         0.978           0.980  \n",
       "21             0.987            0.970         0.987           0.987  \n",
       "22             0.989            0.992         0.985           0.996  \n",
       "23             0.947            0.919         0.939           0.935  \n",
       "24             0.931            0.925         0.940           0.939  \n",
       "25             0.955            0.962         0.982           0.974  \n",
       "26             0.963            0.948         0.983           0.962  \n",
       "27             0.978            0.969         0.958           0.972  \n",
       "28             0.965            0.959         0.974           0.969  \n",
       "29             0.956            0.954         0.974           0.948  \n",
       "30             0.967            0.978         0.971           0.971  "
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write the results to a dataframe\n",
    "review_summary = pd.DataFrame(review)\n",
    "review_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a file name\n",
    "xlx_name = 'pilots_random_forest_results.xlsx'\n",
    "\n",
    "#save to excel\n",
    "review_summary.to_excel('./model_results/' + xlx_name, sheet_name='random_forest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
